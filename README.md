# Terrenator's readme <img src="https://upload.wikimedia.org/wikipedia/commons/a/ab/Flag_of_Panama.svg" alt="Bandera de PanamÃ¡" width="30"/>
![TERRENATOR (30 x 18 cm) (25 x 6 cm) (1)](https://github.com/user-attachments/assets/5c56937c-a3a7-425d-ac0a-d61c6865f1eb)
                
This is the official repository of the TERRENATOR team, which is representing Panama in the World Robotics Olympics (WRO) 2024 to be held this year in Izmir, TÃ¼rkiye. We chose to participate in the category of Future Engineers this year winning first place in the national robotics olympics in our country. In this repository you can find everything related to the development of our robot.

## Team members ðŸ‘¨â€ðŸ’»
> David Rico

> Ericka Ceballos

> Jean Paul Sosa



## Overview of our repository ðŸ“œ
* `schemes`- contains the circuit diagram.
* `others`-  This is for other files which can be used to understand the making of the vehicle. 
* `models` - includes all the 3d printed parts of the robot.
* `src` - the codes for both challenges, with and without obstacles.
* `t-photos` - photos of the team one formal and a funny one.
* `v-photos` - photos of every angle of the robot, including our previuos version .
* `video` - the link to our youtube channel where you can see our robot in action completing both challenges.
* `README.md` - Here's all our journey in the development of our robot here we explain every part of the robot making.

## Components ðŸ§±
A list of all the electrical and mechanical components in the robot.

| <img src="https://github.com/user-attachments/assets/3312d4d8-3a2c-48f9-8fe6-120640876eb5" alt="Alt 1" width="300"/> | <img src="https://github.com/user-attachments/assets/989e28c3-e055-45da-b284-13386d09e14e" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/ddaac9e1-450c-4d3a-bbb0-b5ebca198fa2" alt="Alt 1" width="200"/> | 
| :------------: |:-------------:| :----------:|
|[Arduino NANO A000005 x1](https://store-usa.arduino.cc/products/arduino-nano?srsltid=AfmBOooU4-IrktQwXymxJgaV7MZPj3cBWDjg6AjQwBmYoQw8es2bz9ex)|[LTC1871 Booster Step x1](https://www.amazon.es/ICQUANZX-Converter-3-5-35VDC-Volt%C3%ADmetro-alimentaci%C3%B3n/dp/B07JL39RK2?language=en_GB)|[Step down LM2596 x1](https://a.co/d/e4jJKCS)|
| <img src="https://github.com/user-attachments/assets/b97f68dd-48d3-46a2-872b-7ddec7fb7df7" width="200"/> | <img src="https://github.com/user-attachments/assets/a8fcd7e0-c196-4b7e-b5ac-055d313b8194" alt="Alt 1" width="150"/> | <img src="https://github.com/user-attachments/assets/6791452a-f339-4d2d-ac77-07d16e8cec6d" alt="Alt 1" width="200"/> |
| [Double Sided Prototype Universal PCB Board x2](https://a.co/d/9mUTqVe) |[TB6612 motor driver](https://a.co/d/fpJSHg1)|[HC-SRO4 ultrasonic sensor x3](https://a.co/d/et6RN4v) |
| <img src="https://github.com/user-attachments/assets/22b69b73-122f-42be-bf56-a7297b1bbb23" width="350"/> |<img src="https://github.com/user-attachments/assets/dc905c65-28e3-42ff-bdde-d905bd22bd75" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/dc0bdda4-aeda-43e9-b355-616e628742ca" alt="Alt 1" width="250"/> |
|[POLOLU Metal Gearmotor 25Dx65L mm MP 12V with 48 CPR Encoder x1](https://www.pololu.com/product/4863)|[INJORA 7KG 2065 micro servo motor x1](https://a.co/d/3OIRFif)|[Tosiicop Airsoft Lipo Battery 11.1V x1](https://a.co/d/4mkS5gP)|
| <img src="https://github.com/user-attachments/assets/75af90ba-1501-44d0-9cf9-13ee83422d15" width="250"/> | <img src="https://github.com/user-attachments/assets/1f0feb97-1b34-44a4-a4b9-ae579832d1af" alt="Alt 1" width="300"/> | <img src="https://github.com/user-attachments/assets/166d29d3-77c1-43ee-b914-0fc7dd4190bc" alt="Alt 1" width="200"/> |
|[Pixy cam v2.1 x1](https://a.co/d/hyOCC5F) | 3d structure (you can find the printables in `models`)|[Toggle-Switch SPDT 6A/125VAC x1](https://a.co/d/65AaiQM) |

## Introduction ðŸŽ“

- For make all the structure of the robot, it took a loot of time and investigation, we decided to build our robot totally by our self, we develop the robot in [OnShape](https://www.onshape.com/en/) Platform , all the design of the robot and all the models and pieces can be found here in `models`, it is compound by 17 parts that together make an assembly. We have passed by a lot of prototypes, we are trying with the turkiye prototype, to make it more light, more smaller, more efficient, we are looking to make the things simple, to make the most efficient freelance car, to control our vehicle, we decided to use [Arduino Nano](https://store.arduino.cc/products/arduino-nano) , because it's smaller and has all that we need to control our robot, we have use a various types of Arduino nano, Like the [Arduino Nano ESP32](https://store.arduino.cc/products/nano-esp32), [Arduino Nano Every](https://store.arduino.cc/products/arduino-nano-every), [Arduino Nano Every](https://store.arduino.cc/products/arduino-nano-every). The reason of why we have used various types of arduino nano, is because everyone of them give different capacities, and sometimes we need different capacities in our robot. To understand the making and the programming of the robot please check all the parts of this `README.md`.

## Vehicle Photos ðŸ“¸

| Front           | Right       | Back      |
|:---------------:|:-----------:|:---------:|
| <img width="270" alt="front" src="https://github.com/user-attachments/assets/6f84ca38-0c9e-4d97-ad21-b614274d8c4e"> |<img width="270" alt="front" src="https://github.com/user-attachments/assets/59202f6a-d770-4736-b8df-182cf425b596"> |  <img width="270" alt="front" src="https://github.com/user-attachments/assets/1af8d922-91d6-4d32-9e84-6485ce99b156"> |
| Left          | Top       | Bottom     |
|<img width="270" alt="front" src="https://github.com/user-attachments/assets/3dbc8d78-e1a2-4efd-a434-4e5be9ccd376">| <img width="270" alt="front" src="https://github.com/user-attachments/assets/598fb7a0-45b2-45e9-be24-0b379a4eb9d0"> | <img width="270" alt="front" src="https://github.com/user-attachments/assets/bf297d46-d3c8-4b30-bc6e-63b9df7a281d">|

<br>
 <br>


 > [!NOTE]
>These photos are of the vehicle that will travel to Turkey to participate in WRO 2024, to see the photos of the car that won the robotics olympics in Panama you can go to the photos folder of the vehicle by clicking [here](https://github.com/kieviceb/TERRENATOR-WRO-2024/tree/main/v-photos)


<br>

## Mobility Strategy ðŸš²

### 1- Movement

- Motor: Our  gearmotor consists of a medium-power, 12 V brushed DC motor combined with a 20.4:1 metal spur gearbox, and it has an integrated 48 CPR quadrature encoder on the motor shaft, which provides 979.62 counts per revolution of the gearboxâ€™s output shaft. The gearmotor is cylindrical, with a diameter just under 25 mm, and the D-shaped output shaft is 4 mm in diameter and extends 12.5 mm from the face plate of the gearbox, you can find our motor [here](https://www.pololu.com/product/4863).

<p align="center">
  <img src="https://github.com/user-attachments/assets/d121cff4-57bb-49ff-abe9-caa6e58045c4" alt="Imagen 1" width="500">
</p>

We used a 3D printed traction system in the back axle of the car, is specifically designed to enhance performance and maneuverability. This system involves a set of precisely engineered gears that provide consistent and reliable power transfer from the motor to the rear wheels. The gear configuration ensures that torque is effectively distributed, enabling the car to maintain traction even during rapid acceleration. It provides the power, control, and reliability needed for the commpetition.

### 2- Steering
 
- Steering: The steering is handled by a servomotor, during this project we discovered that using a plastic gear servo is not a good choice, because of the speed of the robot, it tends to break easily inside; thats how we ended up using at first a MG995 servo which is metal gear so it doesnt break so easily, finally for the last prototype to reduce weight and size we found a micro metal gear servo (INJORA 7KG 2065 micro servo motor) , with the power of the big one but weighting less and smaller. Having the steering on the front axle, in vertical position to make movement with more precission.  

<p align="center">
  <img src="https://github.com/user-attachments/assets/c44aed28-b9c0-4dab-8f1e-8f0ccee451fe" alt="Imagen 1" width="250">
  <img src="https://github.com/user-attachments/assets/22066840-dcbf-4895-86de-d436bbadb6e4" alt="Imagen 2" width="510">
</p>



### 3- Sensors

- [HC-SR04](https://www.sparkfun.com/products/15569):
The HC-SR04 is a distance sensor that uses ultrasound to determine the distance of an object in a range of 2 to 450 cm. It is notable for its small size, low power consumption and good accuracy. The HC-SR04 sensor is the most widely used ultrasonic sensor, mainly due to the amount of information and projects available on the web. It is also the most used in robotics projects such as maze or sumo robots, and in automation projects such as level or distance measurement systems.

This sensor provides 2cm to 400cm of non-contact measurement functionality with a ranging accuracy that can reach up to 3mm. Each HC-SR04 module includes an ultrasonic transmitter, a receiver and a control circuit.

<p align="center">
  <img src="https://github.com/user-attachments/assets/ebde91d6-f7ea-45eb-9816-166295341db8" alt="Imagen 1" width="200">
</p>

-How the HC-SR04 Ultrasonic Distance Sensor Works?
It emits an ultrasound at 40 000 Hz which travels through the air and if there is an object or obstacle on its path It will bounce back to the module. Considering the travel time and the speed of the sound you can calculate the distance.

<p align="center">
<img width="500" alt="AJAJ" src="https://github.com/user-attachments/assets/45b9542d-05ac-4dab-ba9b-becfa1949fe0">
</p>

In order to generate the ultrasound we need to set the Trig pin on a High State for 10 Âµs. That will send out an 8 cycle ultrasonic burst which will travel at the speed of sound. The Echo pins goes high right away after that 8 cycle ultrasonic burst is sent, and it starts listening or waiting for that wave to be reflected from an object.

To detect the walls with the HC-SR04 it took us a lot of time to figure out a way of using the ultrasonic sensors to avoid the walls successfully, in our previous prototype we had the sensor horizontally and it gave us good lectures most of the time, but not always, thast way investigating a little further and using trigonometry we found out that position the ultrasonic sensors of the sides vertically is way more effective and the main reason we were having trouble at the curves, what was happening was that the TX and RX sides, when reaching the curves, one was further ahead than the other and the pulse did not reach the same place and was sending out erroneous data, therefore when placing them vertically this does not happen, both pulses collide equally, and the signal bounces back uniformly, sending out useful data.

<p align="center">
<img src="https://github.com/user-attachments/assets/da479d5d-0a66-4abc-842d-d36a51ef9c10" alt="Imagen 1" width="500">
</p> 

- [MPU-6050](https://invensense.tdk.com/products/motion-tracking/6-axis/mpu-6050/):
MPU6050 sensor module is complete 6-axis Motion Tracking Device. It combines 3-axis Gyroscope, 3-axis Accelerometer and Digital Motion Processor all in small package. Also, it has additional feature of on-chip Temperature sensor. It has I2C bus interface to communicate with the microcontrollers. It has Auxiliary I2C bus to communicate with other sensor devices like 3-axis Magnetometer, Pressure sensor etc. If 3-axis Magnetometer is connected to auxiliary I2C bus, then MPU6050 can provide complete 9-axis Motion Fusion output.
<p align="center">
<img src="https://github.com/user-attachments/assets/f120b572-a1a5-462f-a138-078959369f91" alt="Imagen 1" width="200">
</p> 

- Orientation and polarity of the axes and rotations of the MPU-6050:
It is a 6-axis motion sensor that measures linear accelerations and angular velocities. It uses a three-dimensional coordinate system with axes labeled +X, +Y and +Z, representing forward/backward, left/right and up/down directions, respectively. The +X axis points to the right, +Y points up and +Z points vertically away from the top surface of the sensor, with their negative counterparts in the opposite directions. Rotational motions are measured around these axes, with positive rotation defined by the right-hand rule: if the fingers of the right hand are bent in the direction of rotation, the thumb points along the positive axis. For example, clockwise rotation around the +X (roll), +Y (pitch) or +Z (yaw) axes is considered positive, while counterclockwise rotation is negative. This configuration allows the MPU-6050 to track motion in 3D, making it essential for applications such as balancing robots, drones or any system that requires accurate tracking of motion and orientation.
<p align="center">
<img src="https://github.com/user-attachments/assets/2ade620d-4395-4257-9a37-d1a50e8ead96" alt="Imagen 1" width="200">
</p> 
For our vehicle, we are only interested in the z-axis (Yaw) of the MPU-6050, because this axis is the one that will allow us to determine the desired angles for our robot to work, in our vehicle, we have to let the sensor calibrate to start, at the time of being calibrated the angles that we are interested in are those of 90 degrees to be able to make a right angle turn and to help stabilize the PD, because we had the problem that in the straight lines the PD is well stabilized, but when making the curves it went crazy, and began to oscillate a lot, then to have more precise turns, We used the Z axis (Yaw) of the MPU-6050, but this also had its complications, because the values sent by the z axis were not so simple for the robot to understand, because the first curve, if they were 90 degrees, but the next curve for example the gyroscope threw 180 degrees, and if it is logical, but it was more difficult to implement, so we thought of several possible solutions for this, we thought of resetting or resetting the values of Yaw or the z-axis after each curve, so that if in the serial we can always see that it turns 90 degrees exactly, but this greatly affected the accuracy of the sensor.

 <br>
 <br>


 > [!NOTE]
>In order to see the coding of each motion component or sensor explained, please go to the coding part for further understanding, as well as you can always review the vehicle circuit diagram and review the component list, and also you can check our youtube channel. [Here](https://www.youtube.com/@TERRENATORTEAM)


<br>
In this way, in the vehicle, the MPU-6050 works using the desired angles through functions so that the robot can make precise turns. I will go into much more detail about this in the code section.

### 4- Camera

- - [PIXY CAM 2.1](https://pixycam.com/2021/05/20/introducing-pixy-2-1/): 


## Chasis & 3D Parts


  


## Code & programming



## References
- [Git Hub Readme Syntax](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
- https://howtomechatronics.com/tutorials/arduino/ultrasonic-sensor-hc-sr04/
- https://www.sparkfun.com/products/15569
- https://invensense.tdk.com/products/motion-tracking/6-axis/mpu-6050/
- https://pixycam.com/2021/05/20/introducing-pixy-2-1/
- https://wro-association.org/wp-content/uploads/WRO-2023-Future-Engineers-Self-Driving-Cars-General-Rules.pdf
