# Terrenator's readme <img src="https://upload.wikimedia.org/wikipedia/commons/a/ab/Flag_of_Panama.svg" alt="Bandera de Panam√°" width="30"/>
![TERRENATOR (30 x 18 cm) (25 x 6 cm) (1)](https://github.com/user-attachments/assets/5c56937c-a3a7-425d-ac0a-d61c6865f1eb)

[![Facebook](https://img.shields.io/badge/YouTube-%23E4445F.svg?style=for-the-badge&logo=Youtube&logoColor=white)](https://www.youtube.com/@TERRENATORTEAM)
[![Instagram](https://img.shields.io/badge/Instagram-%23E9805F.svg?style=for-the-badge&logo=Instagram&logoColor=white)](https://www.instagram.com/terrenatorteam/)
                
This is the official repository of the TERRENATOR team, which is representing Panama in the World Robotics Olympics (WRO) 2024 to be held this year in Izmir, T√ºrkiye. We chose to participate in the category of Future Engineers this year winning first place in the national robotics olympics in our country. In this repository you can find everything related to the development of our robot.

---

## Team members üë®‚Äçüíª

<img src="https://github.com/user-attachments/assets/b320a2f7-4b2c-4409-85b7-ca4b43df1ef7" alt="Imagen 1" width="700">

 ## David Rico:
 ### Age: 17
 
 David is someone who always tries to solve and constantly seeks the union in the team, he likes sports specifically baseball and likes anime and likes to win.

His role in the team is to design the chassis and 3d parts of the robot, also the circuit and all the components of the robot as well as programming.

## Ericka Ceballos:
### Age: 17
She is very determined and strong, she is always very tidy and organized and above all she doesn't like to lose, ericka likes programming especially in python, she also likes to socialize a lot, as she is the sociable member of the team.

Her role in the team is the programming of the robot, as well as documenting the whole process of the robot.

## Jean Paul Sosa:
### Age: 17


 <img src="https://github.com/user-attachments/assets/20f0f74e-7906-4858-ab06-a2495685e409" alt="Imagen 1" width="400">

He is the quietest of the team, but at the same time he always likes to be neutral in everything, he is someone that you will hardly make him angry, he is a quiet, chill guy. He loves music and enjoys listening to rock and playing instruments like the guitar, bass and saxo, as well as robotics.

His role in the team is to do some of the robot programming as well as help with the circuitry and documenting everything on the robot.

<br>
 <br>


 > [!NOTE]
> To see the funny photo [here](https://github.com/kieviceb/TERRENATOR-WRO-2024/tree/main/t-photos)


<br>


## Overview of our repository üìú
* `schemes`- contains the circuit diagram.
* `models` - includes all the 3d printed parts of the robot that will go to the international.
* `old models` - includes all the 3d printed parts of the robot that wins in Panama.
* `others`-  This is for other files which can be used to understand the making of the vehicle. 
* `src` - the codes for both challenges, with and without obstacles.
* `t-photos` - photos of the team one formal and a funny one.
* `v-photos` - photos of every angle of the robot, including our previuos version .
* `video` - the link to our youtube channel where you can see our robot in action completing both challenges.
* `README.md` - Here's all our journey in the development of our robot here we explain every part of the robot making.

## Components üß±
A list of all the electrical and mechanical components in the robot.


| <img src="https://github.com/user-attachments/assets/0b6a02dc-9252-42df-a9fa-46742892f98a" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/8e77a2b0-b6ea-4c8d-b3eb-0b56e681f396" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/5759c1c0-6d84-4f4d-907a-5cbe9ee2f24a" alt="Alt 1" width="200"/> | 
| :------------: |:-------------:| :------------:|
|[Arduino NANO A000005 x1](https://store-usa.arduino.cc/products/arduino-nano?srsltid=AfmBOooU4-IrktQwXymxJgaV7MZPj3cBWDjg6AjQwBmYoQw8es2bz9ex)|[MPU6050 Gyroscope x1](https://a.co/d/42jYlB6)|[Step down LM2596 x1](https://a.co/d/e4jJKCS)|
| <img src="https://github.com/user-attachments/assets/b18d0b71-d5d0-44e2-b93b-2b98f50b130e" width="200"/> | <img src="https://github.com/user-attachments/assets/19b0baad-f049-460a-b44f-da65eaff72fe" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/eb89182e-ea3c-44d7-b393-524da5d71a76" alt="Alt 1" width="200"/> |
| [Double Sided Prototype Universal PCB Board x2](https://a.co/d/9mUTqVe) |[TB6612 motor driver](https://a.co/d/fpJSHg1)|[HC-SRO4 ultrasonic sensor x3](https://a.co/d/et6RN4v) |
| <img src="https://github.com/user-attachments/assets/513880ec-f790-4aef-a47f-c8ed698db903" width="200"/> |<img src="https://github.com/user-attachments/assets/e4c588c3-7ddb-41af-b9a1-c38992c0b703" alt="Alt 1" width="200"/>| <img src="https://github.com/user-attachments/assets/94190821-27a9-408e-8576-bd84be9f907c" alt="Alt 1" width="200"/> |
|[POLOLU Metal Gearmotor 25Dx65L mm MP 12V with 48 CPR Encoder x1](https://www.pololu.com/product/4863)|[INJORA 7KG 2065 micro servo motor x1](https://a.co/d/3OIRFif)|[Tosiicop Airsoft Lipo Battery 11.1V x1](https://a.co/d/4mkS5gP)|
| <img src="https://github.com/user-attachments/assets/1f0c7367-52d3-4165-8ea6-b22f3e88f032" width="200"/> | <img src="https://github.com/user-attachments/assets/4d3086fc-fdd9-4947-800d-46909c961654" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/9ce8ac59-2668-4852-ba10-070150a25bd4" alt="Alt 1" width="200"/> |
|[Pixy cam v2.1 x1](https://a.co/d/hyOCC5F) |[Electrolytic Capacitor x2](https://a.co/d/2Hp40r2)|[Rocker switch x1](https://a.co/d/dZaNOAK) |
| <img src="https://github.com/user-attachments/assets/a027eed4-f979-4a64-a0f9-7b02da086671" width="200"/> | <img src="https://github.com/user-attachments/assets/0e4da4f4-ee5b-4876-ae01-5a39e919df58" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/5b3d24e6-3a5f-4243-bc55-937bfcc426c0" alt="Alt 1" width="200"/> |
|[10K ohm Resistor x1](https://a.co/d/g2p8k1C) |[UTP cable CAT6 ](https://a.co/d/9NCzytp)|[Push button x1](https://a.co/d/8YSMDxr) |
| <img src="https://github.com/user-attachments/assets/42004542-2963-4c63-9a00-3c3436a9d0dd" width="200"/> | <img src="https://github.com/user-attachments/assets/9305a521-439d-440e-b3a1-d9f97c2a0cd8" alt="Alt 1" width="200"/> | <img src="https://github.com/user-attachments/assets/d0b32f61-361f-4375-b3a1-cdbcc37469d6" alt="Alt 1" width="200"/> |
|[Fuse Holder Inline screw type x1](https://a.co/d/7VGbSVK) |[Jumper wires x12 ](https://a.co/d/0rLEQiV)|[Ceramic capacitor x3](https://amzn.eu/d/0qPpxa0) |


## Introduction üéì

- For make all the structure of the robot, it took a loot of time and investigation, we decided to build our robot totally by our self, we develop the robot in [OnShape](https://www.onshape.com/en/) Platform , all the design of the robot and all the models and pieces can be found here in `models`, it is compound by 17 parts that together make an assembly. We have passed by a lot of prototypes, we are trying with the turkiye prototype, to make it more light, more smaller, more efficient, we are looking to make the things simple, to make the most efficient freelance car, to control our vehicle, we decided to use [Arduino Nano](https://store.arduino.cc/products/arduino-nano) , because it's smaller and has all that we need to control our robot, we have use a various types of Arduino nano, Like the [Arduino Nano ESP32](https://store.arduino.cc/products/nano-esp32), [Arduino Nano Every](https://store.arduino.cc/products/arduino-nano-every), [Arduino Nano Every](https://store.arduino.cc/products/arduino-nano-every). The reason of why we have used various types of arduino nano, is because everyone of them give different capacities, and sometimes we need different capacities in our robot. To understand the making and the programming of the robot please check all the parts of this `README.md`.

## Vehicle Photos üì∏

| Front           | Right       | Back      |
|:---------------:|:-----------:|:---------:|
| <img width="270" alt="front" src="https://github.com/user-attachments/assets/6f84ca38-0c9e-4d97-ad21-b614274d8c4e"> |<img width="270" alt="front" src="https://github.com/user-attachments/assets/59202f6a-d770-4736-b8df-182cf425b596"> |  <img width="270" alt="front" src="https://github.com/user-attachments/assets/1af8d922-91d6-4d32-9e84-6485ce99b156"> |
| Left          | Top       | Bottom     |
|<img width="270" alt="front" src="https://github.com/user-attachments/assets/3dbc8d78-e1a2-4efd-a434-4e5be9ccd376">| <img width="270" alt="front" src="https://github.com/user-attachments/assets/598fb7a0-45b2-45e9-be24-0b379a4eb9d0"> | <img width="270" alt="front" src="https://github.com/user-attachments/assets/bf297d46-d3c8-4b30-bc6e-63b9df7a281d">|

<br>
 <br>


 > [!NOTE]
>These photos are of the vehicle that will travel to Turkiye to participate in WRO 2024, to see the photos of the car that won the robotics olympics in Panama you can go to the photos folder of the vehicle by clicking [here](https://github.com/kieviceb/TERRENATOR-WRO-2024/tree/main/v-photos)


<br>

---

## Circuit Diagram

<p align="center">
  <img src="https://github.com/user-attachments/assets/3060d1a8-dab2-4dfc-81c6-21b5988e575b" alt="Imagen 1" width="500">
</p>

This circuit diagram represents the connections of a robotic system powered by a battery pack and controlled by an Arduino Nano. It integrates four ultrasonic sensors for obstacle detection, a servo motor for steering, and a DC motor for propulsion via a TB6612 motor driver module. The MPU6050 sensor provides orientation data (gyroscope and accelerometer), likely used for navigation adjustments. A Pixy Cam is included for visual object tracking. Connections include multiple power and ground lines to ensure stable operation, while the battery supplies energy to the motors and sensors. Signal wires link the Arduino to the motor driver, servo, and sensors, ensuring precise control and data flow.

<br>
 <br>


 > [!NOTE]
> To a more detailed explanation go to the schemes readme by clicking [here](https://github.com/kieviceb/TERRENATOR-WRO-2024/tree/main/Schemes)


<br>


---


## Mobility Strategy üö≤

### 1- Movement

- Motor: Our  gearmotor consists of a medium-power, 12 V brushed DC motor combined with a 20.4:1 metal spur gearbox, and it has an integrated 48 CPR quadrature encoder on the motor shaft, which provides 979.62 counts per revolution of the gearbox‚Äôs output shaft. The gearmotor is cylindrical, with a diameter just under 25 mm, and the D-shaped output shaft is 4 mm in diameter and extends 12.5 mm from the face plate of the gearbox, you can find our motor [here](https://www.pololu.com/product/4863).

<p align="center">
  <img src="https://github.com/user-attachments/assets/01ae8f00-7621-4a3b-9e70-5e3ffdf041cc" alt="Imagen 1" width="500">
</p>


We used a 3D printed traction system in the back axle of the car, is specifically designed to enhance performance and maneuverability. This system involves a set of precisely engineered gears that provide consistent and reliable power transfer from the motor to the rear wheels. The gear configuration ensures that torque is effectively distributed, enabling the car to maintain traction even during rapid acceleration. It provides the power, control, and reliability needed for the commpetition.

### 2- Steering
 
- Steering: The steering is handled by a servomotor, during this project we discovered that using a plastic gear servo is not a good choice, because of the speed of the robot, it tends to break easily inside; thats how we ended up using at first a MG995 servo which is metal gear so it doesnt break so easily, finally for the last prototype to reduce weight and size we found a micro metal gear servo (INJORA 7KG 2065 micro servo motor) , with the power of the big one but weighting less and smaller. Having the steering on the front axle, in vertical position to make movement with more precission.  

<p align="center">
  <img src="https://github.com/user-attachments/assets/f614d79b-fe56-4d9f-9050-d6d1e6774f1a" alt="Imagen 1" width="250">
  <img src="https://github.com/user-attachments/assets/e71c2fbd-4cee-4220-b352-7d41fcfda527" alt="Imagen 2" width="510">
</p>



### 3- Sensors

- [HC-SR04](https://www.sparkfun.com/products/15569):
The HC-SR04 is a distance sensor that uses ultrasound to determine the distance of an object in a range of 2 to 450 cm. It is notable for its small size, low power consumption and good accuracy. The HC-SR04 sensor is the most widely used ultrasonic sensor, mainly due to the amount of information and projects available on the web. It is also the most used in robotics projects such as maze or sumo robots, and in automation projects such as level or distance measurement systems.

This sensor provides 2cm to 400cm of non-contact measurement functionality with a ranging accuracy that can reach up to 3mm. Each HC-SR04 module includes an ultrasonic transmitter, a receiver and a control circuit.

<p align="center">
  <img src="https://github.com/user-attachments/assets/ebde91d6-f7ea-45eb-9816-166295341db8" alt="Imagen 1" width="200">
</p>

-How the HC-SR04 Ultrasonic Distance Sensor Works?
It emits an ultrasound at 40 000 Hz which travels through the air and if there is an object or obstacle on its path It will bounce back to the module. Considering the travel time and the speed of the sound you can calculate the distance.

<p align="center">
<img width="500" alt="AJAJ" src="https://github.com/user-attachments/assets/45b9542d-05ac-4dab-ba9b-becfa1949fe0">
</p>

In order to generate the ultrasound we need to set the Trig pin on a High State for 10 ¬µs. That will send out an 8 cycle ultrasonic burst which will travel at the speed of sound. The Echo pins goes high right away after that 8 cycle ultrasonic burst is sent, and it starts listening or waiting for that wave to be reflected from an object.

To detect the walls with the HC-SR04 it took us a lot of time to figure out a way of using the ultrasonic sensors to avoid the walls successfully, in our previous prototype we had the sensor horizontally and it gave us good lectures most of the time, but not always, thast way investigating a little further and using trigonometry we found out that position the ultrasonic sensors of the sides vertically is way more effective and the main reason we were having trouble at the curves, what was happening was that the TX and RX sides, when reaching the curves, one was further ahead than the other and the pulse did not reach the same place and was sending out erroneous data, therefore when placing them vertically this does not happen, both pulses collide equally, and the signal bounces back uniformly, sending out useful data.

<p align="center">
<img src="https://github.com/user-attachments/assets/da479d5d-0a66-4abc-842d-d36a51ef9c10" alt="Imagen 1" width="500">
</p> 

In addition to this, as can be seen in the photos of the vehicle, our ultrasonic sensors each have a Ceramic capacitor, and before explaining why we have it we should know what it is. A ceramic capacitor is a fixed-value capacitor where the ceramic material acts as the dielectric. It is formed by two or more alternating layers of ceramic and a metallic layer that acts as the electrode. The composition of the ceramic material defines the electrical behavior and therefore the applications.

Knowing this, our intention in placing these ceramic lentils or capacitors is to be able to soften the signals of the ultrasonic sensors, so to speak filter the signals, this helped to not protrude peaks in the sound waves transmitted by the ultrasonic sensor and so that all data are received with the greatest possible clarity.

<p align="center">
<img src="https://github.com/user-attachments/assets/21413d63-e98a-49d5-9c78-977b65c0e008" alt="Imagen 1" width="350">
</p> 

- [MPU-6050](https://invensense.tdk.com/products/motion-tracking/6-axis/mpu-6050/):
MPU6050 sensor module is complete 6-axis Motion Tracking Device. It combines 3-axis Gyroscope, 3-axis Accelerometer and Digital Motion Processor all in small package. Also, it has additional feature of on-chip Temperature sensor. It has I2C bus interface to communicate with the microcontrollers. It has Auxiliary I2C bus to communicate with other sensor devices like 3-axis Magnetometer, Pressure sensor etc. If 3-axis Magnetometer is connected to auxiliary I2C bus, then MPU6050 can provide complete 9-axis Motion Fusion output.
<p align="center">
<img src="https://github.com/user-attachments/assets/f120b572-a1a5-462f-a138-078959369f91" alt="Imagen 1" width="200">
</p> 

- Orientation and polarity of the axes and rotations of the MPU-6050:
It is a 6-axis motion sensor that measures linear accelerations and angular velocities. It uses a three-dimensional coordinate system with axes labeled +X, +Y and +Z, representing forward/backward, left/right and up/down directions, respectively. The +X axis points to the right, +Y points up and +Z points vertically away from the top surface of the sensor, with their negative counterparts in the opposite directions. Rotational motions are measured around these axes, with positive rotation defined by the right-hand rule: if the fingers of the right hand are bent in the direction of rotation, the thumb points along the positive axis. For example, clockwise rotation around the +X (roll), +Y (pitch) or +Z (yaw) axes is considered positive, while counterclockwise rotation is negative. This configuration allows the MPU-6050 to track motion in 3D, making it essential for applications such as balancing robots, drones or any system that requires accurate tracking of motion and orientation.
<p align="center">
<img src="https://github.com/user-attachments/assets/2ade620d-4395-4257-9a37-d1a50e8ead96" alt="Imagen 1" width="200">
</p> 
For our vehicle, we are only interested in the z-axis (Yaw) of the MPU-6050, because this axis is the one that will allow us to determine the desired angles for our robot to work, in our vehicle, we have to let the sensor calibrate to start, at the time of being calibrated the angles that we are interested in are those of 90 degrees to be able to make a right angle turn and to help stabilize the PD, because we had the problem that in the straight lines the PD is well stabilized, but when making the curves it went crazy, and began to oscillate a lot, then to have more precise turns, We used the Z axis (Yaw) of the MPU-6050, but this also had its complications, because the values sent by the z axis were not so simple for the robot to understand, because the first curve, if they were 90 degrees, but the next curve for example the gyroscope threw 180 degrees, and if it is logical, but it was more difficult to implement, so we thought of several possible solutions for this, we thought of resetting or resetting the values of Yaw or the z-axis after each curve, so that if in the serial we can always see that it turns 90 degrees exactly, but this greatly affected the accuracy of the sensor.

 <br>
 <br>


 > [!NOTE]
>In order to see the coding of each motion component or sensor explained, please go to the coding part for further understanding, as well as you can always review the vehicle circuit diagram and review the component list, and also you can check our youtube channel. [Here](https://www.youtube.com/@TERRENATORTEAM)


<br>
In this way, in the vehicle, the MPU-6050 works using the desired angles through functions so that the robot can make precise turns. I will go into much more detail about this in the code section.

### 4- [MPU-6050 LIBRARIES](https://invensense.tdk.com/products/motion-tracking/6-axis/mpu-6050/):

 First of all we need to initialize our MPU-6050 We need to declare all the variables for it, and it has some specific libraries that you can find it here:

https://github.com/jrowberg/i2cdevlib
https://github.com/ZHomeSlice/Simple_MPU6050
https://github.com/ZHomeSlice/Simple_Wire

And if you don't know how to install it, you need to watch this video, (it's in spanish):

- [MPU-6050  Youtube](https://www.youtube.com/watch?v=TwFZ4BJUX5c&t=1805s)

But i¬¥ll explain here:
First we need to donwload the I2C Library that will make easy the 12c conection with the arduino nano, this library it¬¥s of free software and multiplatform, and this library complement the wire library with the arduino IDE, so, we need to goon the first link i put here and [here](https://github.com/jrowberg/i2cdevlib) then, in the part of code, the green part on the git hub, we will donwnload the zip, so once it is installed we need to extract the file, once it is extracted, we need to go to the 12cdevlib master folder, then the arduino folder, here are a lot of libraries we can use for different proyects, so here we have to search the 12cdev folder, once we find it we have to select it an copy it, so once we do this we have to go to arduino folder, in most of cases it is set default on document, once there we go to libraries and then we paste 12cdev there.

That was our first library, now we need to download the [Simple_MPU6050](https://github.com/ZHomeSlice/Simple_MPU6050)  library, wich this is most simple to use, so we have to intalle the zip of this library, and then in the arduino IDE we have to install the library there, in other words we have to add the zip file to his library inside the IDE.

Even in this part you might have some problems to initialize and use the code, that¬¥s because in the video they dont say this but we need another library, that is for comunication, espacifically the [Simple_Wire](https://github.com/ZHomeSlice/Simple_Wire), to install it you have to follow the same steps of the second library.

Once we have all the libraries needed, we are ready to use the MPU-6050.

### 4- Camera

- 5-[PIXY CAM 2.1](https://pixycam.com/2021/05/20/introducing-pixy-2-1/):
The PixyCam 2.1 is a fast and versatile vision sensor for DIY robotics, offering significant improvements over its predecessor. Its horizontal field-of-view has been expanded to 80 degrees, allowing it to capture more of the environment in each frame, albeit with minor spherical distortion. The camera features a replaceable M12 lens mount with adjustable focus, enabling it to focus on objects as close as 0.25 inches. It also minimizes chromatic distortion at the edges and boasts an F-stop of 2.0, improving light gathering and reducing pixel noise, resulting in higher detection accuracy. Capable of processing images at 60 frames per second, it updates object positions every 16.7 milliseconds, making it ideal for tracking fast-moving objects or precise line-following. The Color Connected Components (CCC) algorithm allows it to detect objects based on hue and saturation, remaining robust under varying lighting conditions. It supports up to 7 unique color signatures or numerous objects using color codes. While retaining the software, firmware, and features of PixyCam 2, this version is slightly larger but significantly more efficient for detection and tracking tasks.
---
<p align="center">
  <img src="https://github.com/user-attachments/assets/820aed1b-6fa0-4af6-b3b8-ce5495a48d07" alt="Imagen 1" width="330">
  <img src="https://github.com/user-attachments/assets/36c5f9ee-3eb9-4901-be3e-9945540ca827" alt="Imagen 2" width="350">
</p>

<br>
 <br>
 
---


 > [!NOTE]
>In the case of our pixy cam 2.1, we always need to calibrate our camera before the competition in the track of the event, this because as it has happened to us before we always need to check that the pixy cam recognizes well the blocks and the color lines, because it happens that the illumination affects the block detection of the pixy cam, then we always need to enter the track with our laptop using specifically the pixymon program, to be able to know that the signatures are being detected effectively, we to calibrate our pixy cam we need to use a microUSB cable that connect to the laptop to opne the pixymon, thanks.



<br>




## Chasis & 3D Parts

In the chassis and 3D part, you can find all the 3D parts that made up the robot that won in Panama in the old models part.

So the chassis and the design of the car that will go to Turkey took a long time because our ideas were to make the robot of the national competition much smaller, agile, faster and prettier, so we had to make a completely new chassis, in this one changing several parts of the assembly, for example in the steering system, since in our previous robot, the steering system was based on moving a cylinder with teeth that moved a line with teeth that gave direction to the robot, the problem with this steering design was that it is a bit imprecise so, we adopted a steering design similar to the Ackerman steering, and we also changed the servo motor.

---
<p align="center">
  <img src="https://github.com/user-attachments/assets/51482f0d-463b-4997-b058-2ef86033c2ad" alt="Imagen 1" width="305">
  <img src="https://github.com/user-attachments/assets/f4bb0df8-0631-45aa-a332-39191a1dede5" alt="Imagen 2" width="350">
</p>
---

Then for the traction, we have four parts, the big gear for motor that this is the gear that give us the torque to move the robot, we have a game of gears that we can modify in case we need speed or more torque, and we have a fixed drive motor retainer, here we have a support for the motor, and we have the small gear for the drive axle, and we have the traction support.

---
<p align="center">
  <img src="https://github.com/user-attachments/assets/c83ed2f5-87f1-4d6b-8bce-bf20d6079f44" alt="Imagen 1" width="360">
  <img src="https://github.com/user-attachments/assets/7953a24a-1a05-472e-b7c0-25cc03c3624d" alt="Imagen 2" width="350">
</p>

---
Then we have the skeleton: 
Here in the skeleton is the main base chasis of the robot, here we can find in the physical one the motor game with his gears, the servo motor, and the modifications that make the steering have better movements.

And also here we have the main shell, here we can find all that makes our robot, here are all the circuits for the robot and the base for the camera.

---
<p align="center">
  <img src="https://github.com/user-attachments/assets/494ede7c-720d-4730-986b-6f228c7efcc0" alt="Imagen 1" width="320">
  <img src="https://github.com/user-attachments/assets/04a91e91-05f8-4a22-87e1-63df63bba776" alt="Imagen 2" width="350">
</p>

---

Now for the sensors, we have made a lot of support for them, but with this one we made the correct one, it is more outside beacuase they give us better data in this way.

---

<p align="center">
  <img src="https://github.com/user-attachments/assets/9d75d1a6-65fd-44ae-aa53-132b60ba3d92" alt="Imagen 1" width="320">
</p>

---

Now with the wheels, we have designed it by ourself, because in that way we can ajust eveything by ourself and it's so much better in that way. For the traction wheels they are a little bit so more big.

---
<p align="center">
  <img src="https://github.com/user-attachments/assets/c0ed90f5-269b-4e7e-b33b-5cce38890710" alt="Imagen 1" width="320">
  <img src="https://github.com/user-attachments/assets/888879fc-d396-48cf-862a-c55d8efb368a" alt="Imagen 1" width="300">
</p>

<br>
 <br>


 > [!NOTE]
> All this can be find in the main [README](https://github.com/kieviceb/TERRENATOR-WRO-2024/blob/main/README.md) And very important you cand see a tutorial video with voice over with all the structure of the robot by clicking [here](https://www.youtube.com/@TERRENATORTEAM)


<br>


## Code & programming
In this section, we will proceed to explain the codes of the First round and the second round, the codes will be explained SEQUENTIALLY in the SRC folder, but there you will have a more general explanation of the code, in this part of the readme we will break down the code of each component that integrates the code, to have a much clearer and understandable epxlicacion each part of the code. Before going to explain each code of the respective round, there will be a list to know the order in which each part of the code will be explained, and remember to see the sequential explanation, it is in the SRC folder.

## Open Challenge Code:

### 1. **Library Imports**

```ino
#include <Servo.h>
#include "Simple_MPU6050.h"
#include <Wire.h>
```
- **Servo.h**: Used to control a servo motor.
- **Simple_MPU6050.h**: Library for interfacing with the MPU6050 sensor (used for orientation).
- **Wire.h**: Library for I2C communication, necessary for interacting with the MPU6050.

---

### 2. **MPU6050 Configuration**
```ino
#define MPU6050_ADDRESS_AD0_LOW     0x68   // I2C address when AD0 pin is LOW
#define MPU6050_ADDRESS_AD0_HIGH    0x69   // I2C address when AD0 pin is HIGH
#define MPU6050_DEFAULT_ADDRESS     MPU6050_ADDRESS_AD0_LOW  // Default I2C address for the MPU6050

Simple_MPU6050 mpu;  // Create an instance of the MPU6050 object
float yawActual = 0;  // Global variable to store the current Yaw (rotation around the Z-axis)
float yawInicial = 0; // Initial yaw value for reference
```
- Defines the I2C addresses for the MPU6050 sensor, depending on the state of the AD0 pin.
- Initializes the `Simple_MPU6050` object for reading data from the sensor.
- `yawActual` holds the current yaw angle (rotation around the Z-axis).
- `yawInicial` stores the initial yaw value, often used for calculating differences in orientation.

---

### 3. **Servo configuration**
```ino
Servo servoDireccion;  // Servo object to control the steering
int pinServo = 6;      // Pin to which the servo is connected
int anguloIzquierda = 87;  // Angle for left turn
int anguloCentro = 90;      // Angle for straight position (centered)
int anguloDerecha = 105;    // Angle for right turn
int anguloMPU = 0;         // Angle value derived from MPU data
```
Initializes the servo and assigns specific angles for left, center, and right turns; also a derivated angle from the mpu6050.

### 4. **PD Control (Proportional-Derivative Control) Variables**
Before we explain the coding of this, we need to explain what is it:

PD Control (Proportional-Derivative) is a technique in control theory used to adjust the behavior of a system based on:

-The current error (Proportional): How much the system deviates from the desired value at this moment.
-The rate of change of the error (Derivative): How quickly the error is changing over time.

A PD controller is a simplified form of the PID control, omitting the Integral term. It is useful when:

-Accumulated errors (integral term) do not need to be eliminated.
-The system requires fast and stable responses.

Mathematical Function of PD
The output of the controller (referred to as adjustment or correction) is calculated as:
![null-109](https://github.com/user-attachments/assets/fbdc2763-facf-4c3c-83a6-f9a0d5bbe00e)

where Kp is the proportional gain, Kd the derivative gain, the error the difference between the desired value (setpoint) and the current system value and and d multiplied by the error between d its the Derivative of the error, i.e., the rate of change of the error over time.

-Implementation of PD Control in the code:
The code uses a PD controller to dynamically adjust the servo motor angle based on error. Below, I break down each step of its implementation:

float Kp = 2.0;: Defines the proportional gain.

A higher value means that the system responds more aggressively to error.
Too high a value can make the system unstable (oscillate).
float Kd = 1.0;: Defines the derivative gain.

Helps to smooth the system response. If the error is changing rapidly, this term reduces the setting to avoid oscillations.
float lastError = 0;: Variable to store the error of the previous iteration.
```ino
float Kp = 0.63;  // Proportional gain for PD control
float Kd = 0.4;   // Derivative gain for PD control
float alpha = 0.15;  // Smoothing factor for yaw
float lastError = 0; // Stores the last error value for derivative calculation
int curva = 0;      // Counter for curves detected by the robot
const int botonPin = A7;  // Button pin used to start/stop the robot
bool enMarcha = false;    // Robot's state: false = stopped, true = running
```
- **PD control constants** (`Kp` and `Kd`): Used to tune the proportional and derivative responses of the control loop.
- **Yaw smoothing** (`alpha`): A factor used to smooth the yaw (orientation) readings from the MPU6050 to avoid abrupt changes.
- **Button and robot state**: The button on pin `A7` is used to start or stop the robot. `enMarcha` indicates whether the robot is running or stopped.

---

### 5. **Ultrasonic Sensor and MotorPin Setup**

```ino
int trigIzquierdo = 9, echoIzquierdo = 10;  // Left sensor pins
int trigCentro = 15, echoCentro = 14;        // Center sensor pins
int trigDerecho = 7, echoDerecho = 8;        // Right sensor pins

int motorPin1 = 5, motorPin2 = 4, enablePin = 3, standbyPin = 16;  // Motor pins for control
```
- Defines the pins for the three ultrasonic sensors (left, center, right). These are used to detect obstacles.
- Motor control pins: These pins are used to control the motors (direction, enable, and standby).

---

### 6. **Time Control and Blocking Variables**

```ino
unsigned long tiempoUltimaCurva = 0;
const long bloqueoTiempo = 2000;  // Time between turns to avoid continuous turning
int bloqueadorI = 65;  // Blocking threshold for left sensor
int bloqueadorD = 65;  // Blocking threshold for right sensor
```
- `tiempoUltimaCurva`: Stores the last time a curve was detected to prevent rapid consecutive curve turns.
- `bloqueoTiempo`: Time interval (in milliseconds) that defines how often the robot can turn to avoid constant turns.
- `bloqueadorI` and `bloqueadorD`: Thresholds for the left and right sensors to prevent false readings from triggering unnecessary turns.

---

### 7. **MPU6050 Data Processing Function**

```ino
void procesarMPU(int16_t *gyro, int16_t *accel, int32_t *quat, uint32_t *timestamp) {
    Quaternion q;  // Quaternion object to store rotation data
    VectorFloat gravity;  // Gravity vector for accurate yaw calculation
    float ypr[3] = { 0, 0, 0 };  // Yaw, pitch, roll values
    float xyz[3] = { 0, 0, 0 };  // Raw sensor data values

    // Get quaternion, gravity, and yaw-pitch-roll data from the MPU
    mpu.GetQuaternion(&q, quat);
    mpu.GetGravity(&gravity, &q);
    mpu.GetYawPitchRoll(ypr, &q, &gravity);
    mpu.ConvertToDegrees(ypr, xyz);

    // Update the yaw value globally
    yawActual = (int)xyz[0];
}
```
- **`procesarMPU`**: This function processes the MPU6050 data (gyroscope, accelerometer) to extract yaw, pitch, and roll values using quaternions and gravity data. The yaw value (`yawActual`) is updated globally.

---

### 8. **PD Control Initialization**

```ino
void inicializarControlPD() {
    servoDireccion.attach(pinServo);  // Attach the servo to the pin
    //servoDireccion.write(anguloCentro); // Optional: Set the servo to the center position (straight)
}
```
- **`inicializarControlPD`**: Initializes the PD control by attaching the servo to the specified pin and optionally setting it to the center position.

---

### 9. **Servo Control Function**

```ino
void move_steer(int pos) {
    int currentPos = servoDireccion.read();  // Get the current position of the servo
    if (pos > currentPos) {
        // Move the servo to the right (gradually increasing position)
        for (int i = currentPos; i <= pos; i++) {
            servoDireccion.write(i);
            delay(10);  // Small delay to smooth the movement
        }
    } else {
        // Move the servo to the left (gradually decreasing position)
        for (int i = currentPos; i >= pos; i--) {
            servoDireccion.write(i);
            delay(10);  // Small delay to smooth the movement
        }
    }
}
```
- **`move_steer`**: This function smoothly moves the servo to a target position (`pos`). It adjusts the servo's position incrementally (with small delays) to avoid abrupt movements.


### 10. **PD Control Adjustment Function**

```ino
void ajustarAngulo(float error, int anguloDeseado) {
    float derivada = error - lastError;  // Calculate the derivative term (rate of change of error)
    float ajuste = (Kp * error) + (Kd * derivada);  // PD control formula
    lastError = error;  // Update the last error value for the next iteration

    anguloDeseado += ajuste;  // Apply the adjustment to the desired angle
    anguloDeseado = constrain(anguloDeseado, anguloIzquierda, anguloDerecha);  // Constrain the angle to avoid exceeding limits
    move_steer(anguloDeseado);  // Move the servo to the adjusted angle
}
```
- **`ajustarAngulo`**: This function adjusts the steering angle based on the error (difference between desired and actual angles) using the PD control formula. It ensures the angle stays within limits (`anguloIzquierda` and `anguloDerecha`) and moves the servo accordingly.

---
### 11. **Ultrasonic Sensor Distance Measurement**

```ino
long medirDistancia(int trigPin, int echoPin) {
    // Trigger the ultrasonic sensor
    digitalWrite(trigPin, LOW);  // Start with LOW to ensure a clean pulse
    delayMicroseconds(3);
    digitalWrite(trigPin, HIGH);  // Send a HIGH pulse to trigger the sensor
    delayMicroseconds(10);
    digitalWrite(trigPin, LOW);  // End the pulse

    // Measure the duration of the echo pulse
    long duracion = pulseIn(echoPin, HIGH);  // Get the duration of the echo signal
    return duracion * 0.034 / 2;  // Convert the duration into distance (in cm)
}
```
- **`medirDistancia`**: This function triggers the ultrasonic sensor and calculates the distance based on the time it takes for the echo to return.

---

### 12. **Function: `calcularAnguloObjetivoI(int curva)`**

```ino
int calcularAnguloObjetivoI(int curva) {
    if (curva % 4 == 1) return -70;     // Curvas 1, 5, 9, ...
    else if (curva % 4 == 2) return -160; // Curvas 2, 6, 10, ...
    else if (curva % 4 == 3) return 110;   // Curvas 3, 7, 11, ...
    else return 20;                      // Curvas 4, 8, 12, ...
}
```

This function calculates the target angle for the servo motor (or steering mechanism) based on the curve number. The variable `curva` represents the current curve number.
- The function uses the modulo operator (`%`) to determine the remainder when dividing `curva` by 4. This helps categorize the curve into one of four possible cases (1 through 4).
- Based on the result of the modulo operation, the function returns a specific angle for the servo.
Here‚Äôs how the curve number determines the angle:
- **When `curva % 4 == 1`** (i.e., curves 1, 5, 9, ...): The servo will turn to **-70¬∞**.
- **When `curva % 4 == 2`** (i.e., curves 2, 6, 10, ...): The servo will turn to **-160¬∞**.
- **When `curva % 4 == 3`** (i.e., curves 3, 7, 11, ...): The servo will turn to **110¬∞**.
- **When `curva % 4 == 0`** (i.e., curves 4, 8, 12, ...): The servo will turn to **20¬∞**.

### 13. **Function: `calcularAnguloObjetivoD(int curva)`**

```ino
int calcularAnguloObjetivoD(int curva) {
    if (curva % 4 == 1) return 75;     // Curvas 1, 5, 9, ...
    else if (curva % 4 == 2) return 155; // Curvas 2, 6, 10, ...
    else if (curva % 4 == 3) return -105;   // Curvas 3, 7, 11, ...
    else return -15;                      // Curvas 4, 8, 12, ...
}
```
This function also calculates the target angle for the servo motor based on the curve number. The input `curva` represents the current curve number.
Similar to the previous function, the modulo operator (`%`) is used to categorize the curve number, and the function returns a specific angle based on that categorization.
Here‚Äôs how the curve number determines the angle:
- **When `curva % 4 == 1`** (i.e., curves 1, 5, 9, ...): The servo will turn to **75¬∞**.
- **When `curva % 4 == 2`** (i.e., curves 2, 6, 10, ...): The servo will turn to **155¬∞**.
- **When `curva % 4 == 3`** (i.e., curves 3, 7, 11, ...): The servo will turn to **-105¬∞**.
- **When `curva % 4 == 0`** (i.e., curves 4, 8, 12, ...): The servo will turn to **-15¬∞**.
### 14. **Motor control**
Then we will enter the Void functions, which are functions that in determinod time we can call for certain event that we need to occur, in this case the movement of the car, the motorpin 1 in HIGH and motorpin 2 in low makes the motor advance, in case of putting this configuration backwards would make the car go in reverse, and also atravz of the PWM can adjust the speed of the motor, as we can see:
```ino
void avanzar(int velocidad) {
    // Set the motor to rotate in a specific direction.
    digitalWrite(motorPin1, HIGH); // Set motorPin1 to HIGH to define the forward rotation direction.
    digitalWrite(motorPin2, LOW);  // Set motorPin2 to LOW to ensure the motor rotates in the desired direction.
    // Control the motor's speed using PWM (Pulse Width Modulation).
    analogWrite(enablePin, velocidad); // Generate a PWM signal on enablePin to adjust the motor speed (range: 0-255).
}

```
Now we will have the function to stop the motor, that would be with the two pins in LOW, in the code it would be like this:
```ino
void detener() {
    // Stop the motor by cutting power to both motor direction pins.
    digitalWrite(motorPin1, LOW); // Set motorPin1 to LOW to stop the motor.
    digitalWrite(motorPin2, LOW); // Set motorPin2 to LOW to ensure no rotation.

    // Set the speed to zero to fully disable the motor.
    analogWrite(enablePin, 0); // Generate a PWM signal of 0 to turn off the motor.
}
```

### 15. **Function: `detectarCurva(long distanciaIzquierda, long distanciaCentro, long distanciaDerecha)`**
This function is responsible for detecting curves on the path and adjusting the robot's movements to navigate those curves. It uses data from distance sensors (left, center, and right) and a gyroscope to determine the robot's orientation and make real-time adjustments. Below is a step-by-step breakdown of how the function works:
**Input Parameters**:
   - `distanciaIzquierda`: Distance measured by the left sensor.
   - `distanciaCentro`: Distance measured by the center sensor.
   - `distanciaDerecha`: Distance measured by the right sensor.
**Calculating the Error and Sum**:
   - **Error Calculation**:
     ```ino
     float error = distanciaIzquierda - distanciaDerecha;
     ```
     This computes the difference between the distances measured by the left and right sensors. This difference (`error`) indicates whether the robot is closer to the left or right side. A positive error suggests the left sensor detects a closer object, and a negative error suggests the right sensor detects a closer object.

   - **Sum Calculation**:
     ```ino
     float sum = distanciaIzquierda + distanciaDerecha;
     ```
     The sum of the left and right distances gives an overall sense of the space around the robot, used to assess whether there is enough open space to proceed.

   - **Storing Last Error**:
     ```cpp
     lastError = error;
     ```
     The current error is stored for later use (possibly for debugging or future calculations).
**Time Check for Curve Blocking**:
   - **Time Since Last Curve**:
     ```cpp
     unsigned long tiempoActual = millis(); 
     if (tiempoActual - tiempoUltimaCurva >= bloqueoTiempo)
     ```
     This checks whether enough time has passed since the last detected curve (`tiempoUltimaCurva`). The purpose of this is to prevent the robot from continuously detecting curves or making unnecessary turns too quickly. If the time difference exceeds `bloqueoTiempo`, the robot is allowed to detect and adjust to another curve.
**Curve Detection and Navigation**:
   - **Left Turn Detection**:
     ```cpp
     if (error > 1 && distanciaCentro < 58 && sum > 90 && distanciaIzquierda > bloqueadorI) {
     ```
     This condition checks if the robot should turn left:
     - If `error > 1`, it suggests the left side is closer, indicating the need to turn left.
     - If `distanciaCentro < 58`, the center sensor detects something close, indicating the robot is navigating near an obstacle or a curve.
     - If `sum > 90`, the combined distance on the left and right sides suggests there‚Äôs enough room for a curve.
     - If `distanciaIzquierda > bloqueadorI`, the robot ensures it‚Äôs not too close to the left obstacle.
     
     If all these conditions are met, the robot recognizes a left curve and proceeds with the turn:
     - **Increment Curve Counter**: 
       ```cpp
       curva++;
       ```
       The `curva` counter is incremented to keep track of how many curves the robot has encountered.
     - **Calculate Target Angle for Left Turn**: 
       ```cpp
       int anguloObjetivo = calcularAnguloObjetivoI(curva);
       ```
       The function `calcularAnguloObjetivoI()` determines the target angle for the robot to turn to navigate the curve, based on the curve count (`curva`).
     - **Perform the Turn**: 
       ```cpp
       while (abs(yawActual - anguloObjetivo) > 2) {
           servoDireccion.write(119);  // Turn left
           avanzar(250);  // Move forward while turning
       }
       ```
       The robot keeps turning left (by controlling the servo direction) until the current yaw angle (`yawActual`) reaches the target angle (`anguloObjetivo`). A tolerance of 2 degrees is allowed.
     - **Stop Turning and Return to Center**:
       ```cpp
       servoDireccion.write(anguloCentro);
       delay(100);  // Short delay to stabilize
       tiempoUltimaCurva = tiempoActual;  // Update last curve time
       bloqueadorD = 1500;  // Block right turns temporarily
       ```
       After completing the left turn, the robot‚Äôs servo is reset to the center, and a brief delay is added to stabilize. It also updates the time of the last curve and blocks right turns temporarily with `bloqueadorD`.

   - **Right Turn Detection**:
     ```cpp
     else if (error < -1 && distanciaCentro < 58 && sum > 90 && distanciaDerecha > bloqueadorD) {
     ```
     Similar to the left turn detection, but this condition checks if the robot should turn right:
     - If `error < -1`, it suggests the right side is closer, indicating a need to turn right.
     - If `distanciaDerecha > bloqueadorD`, the robot ensures it‚Äôs not too close to the right obstacle.

     The steps for a right turn are almost identical to the left turn, with a few changes:
     - The target angle for the right turn is calculated using `calcularAnguloObjetivoD(curva)`.
     - The robot turns right by writing to the servo with `servoDireccion.write(69)`.

   - **If No Curve is Detected**:
     ```cpp
     else {
         ajustarAngulo(error, anguloCentro);
         avanzar(200);  // Move forward normally
     }
     ```
     If no curve is detected (i.e., neither left nor right conditions are met), the robot simply adjusts its angle to stay centered (`ajustarAngulo()`) and continues moving forward.

**Final else Block**:
If the time since the last curve is not enough (`tiempoActual - tiempoUltimaCurva < bloqueoTiempo`), the robot will again adjust its angle and move forward normally:
```cpp
else {
    ajustarAngulo(error, anguloCentro);
    avanzar(200);  // Move forward normally
}
```
This function helps the robot navigate curves effectively by constantly adjusting its heading and movement based on real-time sensor data.

### 16. **Function: `actualizar()`**
This function updates the sensor readings, checks for curves, and provides debug output on the serial monitor.
```ino
void actualizar() {
    // Measure distances from the left, center, and right sensors
    long distanciaIzquierda = medirDistancia(trigIzquierdo, echoIzquierdo);
    long distanciaCentro = medirDistancia(trigCentro, echoCentro);
    long distanciaDerecha = medirDistancia(trigDerecho, echoDerecho);

    // Call the function to detect a curve based on sensor data
    detectarCurva(distanciaIzquierda, distanciaCentro, distanciaDerecha);

    // If 12 curves have been detected, stop the robot and pause for 60 seconds
    if (curva == 12) {
        servoDireccion.write(90);  // Center the servo
        avanzar(250);  // Move forward briefly
        delay(700);  // Wait for 700 ms
        detener();  // Stop the robot
        delay(60000);  // Wait for 60 seconds
    }

    // Print sensor and robot state data to the serial monitor for debugging
    Serial.print("Yaw: "); Serial.print(yawActual);
    Serial.print(" | Distancia Izquierda: "); Serial.print(distanciaIzquierda);
    Serial.print(" | Distancia Centro: "); Serial.print(distanciaCentro);
    Serial.print(" | Distancia Derecha: "); Serial.print(distanciaDerecha);
    Serial.print(" | Error: "); Serial.println(lastError);
}
```
- **Sensor data**: Reads the distance from the left, center, and right sensors.
- **Curve detection**: Calls the `detectarCurva()` function to check for curves.
- **Robot control**: Stops the robot after 12 curves and pauses for 60 seconds.
- **Debugging output**: Prints useful information (yaw, distances, error) to the serial monitor.
---
### 17. **Function: `setup()`**
This function initializes the robot‚Äôs hardware, including sensors, motors, and communication interfaces.
```ino
void setup() {
    Serial.begin(115200);  // Start serial communication at 115200 baud rate
    
    // Initialize sensor pins (left, center, right sensors)
    pinMode(trigIzquierdo, OUTPUT);
    pinMode(echoIzquierdo, INPUT);
    pinMode(trigCentro, OUTPUT);
    pinMode(echoCentro, INPUT);
    pinMode(trigDerecho, OUTPUT);
    pinMode(echoDerecho, INPUT);

    // Initialize motor control pins
    pinMode(motorPin1, OUTPUT);
    pinMode(motorPin2, OUTPUT);
    pinMode(enablePin, OUTPUT);
    pinMode(standbyPin, OUTPUT);
    digitalWrite(standbyPin, HIGH);  // Set standby pin to HIGH to enable motors
    
    // Initialize PD control system
    inicializarControlPD();

    // Initialize MPU6050 (gyroscope/accelerometer)
    Wire.begin();  // Start I2C communication
    Wire.setClock(400000);  // Set I2C clock speed to 400 kHz
    
    Serial.println(F("Iniciando calibraci√≥n del MPU6050..."));
    mpu.SetAddress(MPU6050_ADDRESS_AD0_LOW)
       .CalibrateMPU()  // Calibrate the MPU6050 sensor
       .load_DMP_Image();  // Load the DMP (Digital Motion Processor) image for data processing
    mpu.on_FIFO(procesarMPU);  // Set up a callback function to process the MPU data from the FIFO buffer
    
    delay(100);  // Wait for the system to stabilize before starting the main loop
}
```

- **Serial communication**: Initializes communication for debugging and monitoring.
- **Sensor pin configuration**: Sets up the pins for the distance sensors.
- **Motor control**: Configures the pins used to control the robot‚Äôs motors.
- **MPU6050 sensor setup**: Initializes and calibrates the MPU6050 sensor to track the robot‚Äôs orientation.
- **Control system initialization**: Sets up the PD controller for motor and servo control.
---
These functions together enable the robot to detect curves, navigate based on sensor data, and output debug information, while ensuring proper initialization and configuration of the robot's hardware.
### 18. **Main Control Loop**

```ino
void loop() {
    if (!enMarcha) {  // If the robot is NOT running
        if (analogRead(botonPin) == 0) {  // If the button is pressed
            enMarcha = true;                   // Change the state to "running"
            Serial.println("Robot running!");
            servoDireccion.write(anguloCentro);  // Center the servo
        } else {
            detener();  // Keep the robot stopped if the button is not pressed
        }
    } 
    if (enMarcha == true) {  // If the robot is running
        mpu.dmp_read_fifo();  // Read data from the MPU6050 sensor
        actualizar();         // Execute PD control for adjusting the steering
        delay(5);             // Small delay for smooth operation
    }
}
```
- **`loop`**: The main loop that continuously checks if the robot is running. If it is running, the loop reads sensor data, adjusts the steering based on PD control, and moves the robot accordingly. If the button is pressed, the robot starts.
---

### Why do we use PD?:
1- To maintain stability: Avoid abrupt movements or overcorrections that could destabilize the robot.

2- To improve precision: Adjust the steering angle based on real-time data, ensuring that the robot follows the desired path.

3- For smooth motion: Thanks to the derivative term, it reduces oscillations, achieving a smooth ride.

4- For adaptability: Responds dynamically to changes in the environment, such as curves or detours, by adjusting the robot's direction.

---

## Second Challenge Code:

To see the complete code go to the [SRC](https://github.com/kieviceb/TERRENATOR-WRO-2024/tree/main/src) File on the git hub.

---

### Libraries and MPU6050 directions
first we need to include all the libraries that we are gonna use for the second challegne code, here we use **`Servo.h`**, **`Pixy2.h`**, **`Simple_MPU6050.h`**, **`Wire.h`**.

Then we have the MPU6050 configurations, first we have the **`MPU6050_ADDRESS_AD0_LOW `** (0X68), this is the default addres of the MPU6050 when the AD0 pin (addres pin) is tied to the ground (logic LOW). Then we have **`MPU6050_ADDRESS_AD0_HIGH `** (0x69), this the alternative address used when the AD0 pin is connected to VCC (logic HIGH). For third we have **`MPU6050_DEFAULT_ADRESS`** (0x68) This macro defines the default I2C address the program will use to communicate with the MPU6050. In this case, it is set to **`MPU6050_ADDRESS_AD0_LOW `**, meaning the AD0 pin is assumed to be connected to ground.

```ino
#include <Servo.h>
#include <Pixy2.h>
#include "Simple_MPU6050.h"
#include <Wire.h>

// Configuraci√≥n MPU6050
#define MPU6050_ADDRESS_AD0_LOW     0x68
#define MPU6050_ADDRESS_AD0_HIGH    0x69
#define MPU6050_DEFAULT_ADDRESS     MPU6050_ADDRESS_AD0_LOW
```

---

### MPU6050, Pixy 2.1, an the Servo initialization:

This section of the code sets up essential components for the robot's operation: the MPU6050 sensor for orientation, the Pixy2 camera for vision processing, and a servo motor for steering.

The Simple_MPU6050 mpu; object is initialized to interface with the MPU6050 sensor, which measures the robot's rotation and acceleration. Two global variables, yawActual and yawInicial, are defined to track the current yaw (rotation around the vertical axis) and the initial yaw value, respectively. These variables are crucial for detecting and responding to changes in the robot's orientation during movement.

The Pixy2 pixy; object is created to control the Pixy2 camera, which can recognize visual patterns or objects. Although its specific use is not detailed in the current code, it is prepared for future tasks related to vision-based navigation or obstacle avoidance.

For steering, the Servo servoDireccion; object is declared. The servo is connected to pin 6, as defined by int pinServo = 6;. Predefined angles are assigned to constants (anguloIzquierda = 87, anguloCentro = 90, and anguloDerecha = 105) to represent left, center, and right steering positions, respectively. These angles ensure precise control of the servo for effective navigation. Additionally, int anguloMPU = 0; is introduced to dynamically adjust the steering angle based on real-time yaw readings from the MPU6050, enabling the robot to correct its path automatically.

This setup provides the foundation for integrating sensor data, visual feedback, and motor control to achieve smooth and responsive robotic movement.

```ino
Simple_MPU6050 mpu;
float yawActual = 0;  // Variable global para almacenar el Yaw actual
// Variable para el yaw
float yawInicial = 0;

// Variables globales del PD
Pixy2 pixy;
Servo servoDireccion;
int pinServo = 6;
int anguloIzquierda = 87;
int anguloCentro = 90;
int anguloDerecha = 105;
int anguloMPU = 0;

```
---

### Variables and Pin Configuration:

PD Controller Variables
Kp = 0.5, Kd = 0.5: PD gains for response and damping.
alpha = 0.15: Smooths steering adjustments.
lastError = 0: Previous error for derivative calculation.
curva = 0: Current turning action.
Robot State and Button
botonPin = A7: Button pin to start/stop movement.
enMarcha = false: Initial movement state (stopped).
anguloSuavizado = anguloCentro: Smoothed steering angle.
Vision Zones
Boundaries for camera detection:

deltaX, epsilonX, and zetaX ranges define vision zones.
Ultrasonic Sensor Pins
Left: trigIzquierdo = 10, echoIzquierdo = 9.
Center: trigCentro = 15, echoCentro = 14.
Right: trigDerecho = 7, echoDerecho = 8.
Motor Pins
motorPin1 = 5, motorPin2 = 4: Motor direction.
enablePin = 3, standbyPin = 16: Motor enable and standby.

```ino
float Kp = 0.5;
float Kd = 0.5;
float alpha = 0.15;
float lastError = 0;
int curva = 0;
const int botonPin = A7;  // Pin del bot√≥n
bool enMarcha = false;    // Estado inicial del robot: detenido
float anguloSuavizado = anguloCentro;

const int deltaXMin = 88, deltaXMax = 98;
const int epsilonXMin = 101, epsilonXMax = 213;
const int zetaXMin = 190, zetaXMax = 274;


// Pines de sensores
int trigIzquierdo = 10, echoIzquierdo = 9;
int trigCentro = 15, echoCentro = 14;
int trigDerecho = 7, echoDerecho = 8;

// Pines de motor
int motorPin1 = 5, motorPin2 = 4, enablePin = 3, standbyPin = 16;

```

---

### 

**`procesarMPU`** Function:
This function processes gyroscope and accelerometer data from the **`MPU6050`** sensor:

1- **`mpu.GetQuaternion`**, **`mpu.GetGravity`**, and **`mpu.GetYawPitchRoll`**: Extract quaternion, gravity vector, and yaw-pitch-roll angles.
2- **`mpu.ConvertToDegrees`**: Converts yaw-pitch-roll angles from radians to degrees.
3- Updates **`yawActual`**: The current yaw angle is stored globally for robot orientation.

This function ensures the robot can interpret and use orientation data for navigation and control.

**`inicializarControlPD Function
This function sets up the PD control by initializing the servo:

1- **`servoDireccion.attach(pinServo)`**: Links the servo to the specified pin for directional control.
2- Optionally centers the steering using a commented **`move_steer(anguloCentro)`** call, which positions the servo to a neutral angle.
It prepares the robot for smooth and precise directional adjustments.

**`move_steer`** Function
This function controls the servo motor for gradual steering adjustments:

1- Reads the current servo position using **`servoDireccion.read()`**.
2- If the target position is greater than the current position, the servo angle is incremented.
3- If the target position is smaller, the servo angle is decremented.
4- **`delay(10)`** ensures smooth transitions without abrupt movements.
This gradual movement prevents sudden turns, improving robot stability and precision during navigation.

```ino
// Funci√≥n para procesar datos del MPU6050
void procesarMPU(int16_t *gyro, int16_t *accel, int32_t *quat, uint32_t *timestamp) {
    Quaternion q;
    VectorFloat gravity;
    float ypr[3] = { 0, 0, 0 };
    float xyz[3] = { 0, 0, 0 };
    
    mpu.GetQuaternion(&q, quat);
    mpu.GetGravity(&gravity, &q);
    mpu.GetYawPitchRoll(ypr, &q, &gravity);
    mpu.ConvertToDegrees(ypr, xyz);
    
    yawActual = (int)xyz[0];  // Actualizar el Yaw global
}
//*******
void inicializarControlPD() {
    servoDireccion.attach(pinServo);
    //move_steer(anguloCentro);
}
//*******
void move_steer(int pos) {
    int currentPos = servoDireccion.read();
    if (pos > currentPos) {
        for (int i = currentPos; i <= pos; i++) {
            servoDireccion.write(i);
            delay(10);
        }
    } else {
        for (int i = currentPos; i >= pos; i--) {
            servoDireccion.write(i);
            delay(10);
        }
    }
}
```

---

### Functions for angle adjustment and distant measurement:

ajustarAngulo Function
This function adjusts the steering angle using PD control:

error and derivada calculate the proportional and derivative terms.
The angle is updated based on the error and constrained between anguloIzquierda and anguloDerecha.
move_steer(anguloDeseado) applies the adjusted angle.
It helps maintain smooth and precise steering.

medirDistancia Function
This function measures the distance using an ultrasonic sensor:

It triggers the sensor and calculates the distance based on the pulse duration.
It provides distance data for obstacle detection or navigation.

Angle Calculation Functions
calcularAnguloObjetivoI, calcularAnguloObjetivoDC, calcularAnguloObjetivoIC, and calcularAnguloObjetivoD Functions
These functions calculate the target steering angles for various curve types. The angle depends on the curva value:

Each curve type (based on curva % 4) has a unique angle to handle different turns.

```ino
//*******
void ajustarAngulo(float error, int anguloDeseado) {
    float derivada = error - lastError;
    float ajuste = (Kp * error) + (Kd * derivada);
    lastError = error;
    
    anguloDeseado += ajuste;
    anguloDeseado = constrain(anguloDeseado, anguloIzquierda, anguloDerecha);
    move_steer(anguloDeseado);
}
//*******
long medirDistancia(int trigPin, int echoPin) {
    digitalWrite(trigPin, LOW);
    delayMicroseconds(3);
    digitalWrite(trigPin, HIGH);
    delayMicroseconds(10);
    digitalWrite(trigPin, LOW);

    long duracion = pulseIn(echoPin, HIGH);
    return duracion * 0.034 / 2;
}
//*******

// Funci√≥n para calcular el √°ngulo objetivo
int calcularAnguloObjetivoI(int curva) {
    if (curva % 4 == 1) return -75;     // Curvas 1, 5, 9, ...
    else if (curva % 4 == 2) return -165; // Curvas 2, 6, 10, ...
    else if (curva % 4 == 3) return 105;   // Curvas 3, 7, 11, ...
    else return 15;                      // Curvas 4, 8, 12, ...
}

//*******

// Funci√≥n para calcular el √°ngulo objetivo
int calcularAnguloObjetivoDC(int curva) {
    if (curva % 4 == 1) return 90;     // Curvas 1, 5, 9, ...
    else if (curva % 4 == 2) return 180; // Curvas 2, 6, 10, ...
    else if (curva % 4 == 3) return -90;   // Curvas 3, 7, 11, ...
    else return 0;                      // Curvas 4, 8, 12, ...
}

//*******

// Funci√≥n para calcular el √°ngulo objetivo
int calcularAnguloObjetivoIC(int curva) {
    if (curva % 4 == 1) return -90;     // Curvas 1, 5, 9, ...
    else if (curva % 4 == 2) return -180; // Curvas 2, 6, 10, ...
    else if (curva % 4 == 3) return 90;   // Curvas 3, 7, 11, ...
    else return 0;                      // Curvas 4, 8, 12, ...
}

//*******

// Funci√≥n para calcular el √°ngulo objetivo
int calcularAnguloObjetivoD(int curva) {
    if (curva % 4 == 1) return 75;     // Curvas 1, 5, 9, ...
    else if (curva % 4 == 2) return 165; // Curvas 2, 6, 10, ...
    else if (curva % 4 == 3) return -105;   // Curvas 3, 7, 11, ...
    else return -15;                      // Curvas 4, 8, 12, ...
}
```

---

### Motor Control Functions

avanzar Function
This function controls the forward movement of the robot:

1- motorPin1 is set to HIGH and motorPin2 to LOW, which activates the motor in the forward direction.
2- analogWrite(enablePin, velocidad) controls the motor speed by applying a PWM signal to the enable pin.
This function allows the robot to move forward at a specified speed.

retroceder Function
This function handles the backward movement of the robot:

1- motorPin1 is set to LOW and motorPin2 to HIGH to drive the motor in reverse.
2- analogWrite(enablePin, velocidad) adjusts the reverse speed of the motor using a PWM signal.
It enables the robot to move backward with the desired speed.

detener Function
This function stops the robot:

1- It sets both motorPin1 and motorPin2 to LOW, turning off the motor.
2- analogWrite(enablePin, 0) disables the motor by setting the PWM signal to 0.

```ino
//*******
void avanzar(int velocidad) {
    digitalWrite(motorPin1, HIGH);
    digitalWrite(motorPin2, LOW);
    analogWrite(enablePin, velocidad);
}
//*******
void retroceder(int velocidad) {
    digitalWrite(motorPin1, LOW);
    digitalWrite(motorPin2, HIGH);
    analogWrite(enablePin, velocidad);
}
//*******

void detener() {
    digitalWrite(motorPin1, LOW);
    digitalWrite(motorPin2, LOW);
    analogWrite(enablePin, 0);
}
```

---

## References
- [Git Hub Readme Syntax](https://docs.github.com/en/get-started/writing-on-github/getting-started-with-writing-and-formatting-on-github/basic-writing-and-formatting-syntax)
- https://howtomechatronics.com/tutorials/arduino/ultrasonic-sensor-hc-sr04/
- https://www.sparkfun.com/products/15569
- https://invensense.tdk.com/products/motion-tracking/6-axis/mpu-6050/
- https://pixycam.com/2021/05/20/introducing-pixy-2-1/
- https://wro-association.org/wp-content/uploads/WRO-2023-Future-Engineers-Self-Driving-Cars-General-Rules.pdf
- https://www.onshape.com/en/
-https://www.matthewpeterkelly.com/tutorials/pdControl/index.html#:~:text=A%20proportional%2Dderivative%20(PD),car%20at%20some%20desired%20height.
- https://www.youtube.com/watch?v=TwFZ4BJUX5c&t=1805s
- https://grabcad.com/library/pixycam2-case-2
